{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc7be5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\43460\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de68f85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å·²ç”Ÿæˆ tag2id.jsonï¼Œæ ‡ç­¾æ•°ï¼š 668\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# æ›¿æ¢ä¸ºä½ æœ¬åœ°çš„è®­ç»ƒé›†è·¯å¾„\n",
    "train_path = \"train_data.jsonl\"\n",
    "\n",
    "tag_set = set()\n",
    "\n",
    "with open(train_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line.strip())\n",
    "        tag_set.update(data.get(\"label_tags\", []))\n",
    "\n",
    "tag2id = {tag: i for i, tag in enumerate(sorted(tag_set))}\n",
    "\n",
    "# ä¿å­˜\n",
    "with open(\"tag2id.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(tag2id, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"âœ… å·²ç”Ÿæˆ tag2id.jsonï¼Œæ ‡ç­¾æ•°ï¼š\", len(tag2id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "123d7fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½æ ‡ç­¾æ˜ å°„\n",
    "with open(\"tag2id.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    tag2id = json.load(f)\n",
    "id2tag = {i: tag for tag, i in tag2id.items()}\n",
    "num_labels = len(tag2id)\n",
    "\n",
    "# å®šä¹‰æ¨¡å‹ç»“æ„ï¼ˆä¸è®­ç»ƒä¸€è‡´ï¼‰\n",
    "class BERTTagRecommender(nn.Module):\n",
    "    def __init__(self, model_name, output_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.encoder.config.hidden_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, output_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        return self.classifier(output.pooler_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30277103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERTTagRecommender(\n",
       "  (encoder): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=384, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=668, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = BERTTagRecommender(model_name, num_labels)\n",
    "model.load_state_dict(torch.load(\"checkpoint_model.pt\", map_location=torch.device(\"cpu\")))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5629606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tags(context_tags, target_character, top_k=8):\n",
    "    text = \", \".join(context_tags) + \" [SEP] \" + target_character\n",
    "    encoded = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=64)\n",
    "    with torch.no_grad():\n",
    "        logits = model(encoded[\"input_ids\"], encoded[\"attention_mask\"])\n",
    "        probs = torch.sigmoid(logits).squeeze().numpy()\n",
    "    top_indices = probs.argsort()[::-1][:top_k]\n",
    "    return [(id2tag[i], float(probs[i])) for i in top_indices if probs[i] > 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e2d9218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ æ¨èæ ‡ç­¾ï¼š [('hair_between_eyes', 0.9984135627746582), ('white_flower', 0.9977719187736511), ('flower', 0.9949317574501038), ('hair_flower', 0.9917808175086975), ('hair_ornament', 0.9823211431503296), ('yellow_eyes', 0.9625009894371033), ('short_hair_with_long_locks', 0.9360777139663696), ('blonde_hair', 0.8160218000411987)]\n"
     ]
    }
   ],
   "source": [
    "# ä¾‹ï¼šæŠŠ ganyu_(genshin_impact) çš„ prompt æ›¿æ¢ä¸º lumine_(genshin_impact) é£æ ¼\n",
    "context_tags = [\n",
    "    \"1girl\", \"ahoge\", \"bare shoulders\",\"cleavage\",\"breasts\",\"flower\",\"dress\",\"looking_at_viewer\", \"bell\", \"blinking\", \n",
    "    \"blue hair\", \"blush\",  \"purple eyes\"\n",
    "]\n",
    "\n",
    "target_character = \"lumine_(genshin_impact)\"\n",
    "\n",
    "result = predict_tags(context_tags, target_character)\n",
    "print(\"ğŸ¯ æ¨èæ ‡ç­¾ï¼š\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
